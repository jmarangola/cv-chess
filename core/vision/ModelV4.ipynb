{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIDOn8EY0neI",
        "outputId": "5cebf433-70c4-4b1a-adcd-27e808575f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "%tensorflow_version 1.x\n",
        "import torchvision.models as models\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOY1HmKc0xZJ",
        "outputId": "68a15e2d-2d38-4913-e1d2-b7d85ec7227f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G-lIVu3W1T9L"
      },
      "outputs": [],
      "source": [
        "foldername = '/content/drive/MyDrive/data_done/' \n",
        "train = pd.read_csv(foldername + 'my_csv.csv', names=['id','piece'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RettlkNL1wcj"
      },
      "outputs": [],
      "source": [
        "np.random.seed(123)\n",
        "\n",
        "def data_split(N, ratio=[8,2]):\n",
        "  # generate a shuffle array\n",
        "  shuffle_idx = np.arange(N)\n",
        "  np.random.shuffle(shuffle_idx)\n",
        "  # divide into train-val-test by the ratio\n",
        "  data_split = (np.cumsum(ratio)/float(sum(ratio))*N).astype(int)\n",
        "  out_idx = [None] * len(ratio)\n",
        "  out_idx[0] = shuffle_idx[:data_split[0]]\n",
        "  for i in range(1,len(ratio)):\n",
        "    out_idx[i] = shuffle_idx[data_split[i-1] : data_split[i]]\n",
        "  return out_idx  \n",
        "\n",
        "\n",
        "#splitting into 8:2 ratio\n",
        "split_idx = data_split(len(train))\n",
        "df_train = train.loc[split_idx[0]]\n",
        "df_valid = train.loc[split_idx[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ln_v6kAN1Ysy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "metadata_cols = train.columns[1:-1]\n",
        "# make a child class of PyTorch's dataset class\n",
        "class ChessDataset(Dataset):\n",
        "    def __init__(self, root_dir, df, transforms=None):\n",
        "        # initialization: called only once during creation\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.file_names = df['id'].values\n",
        "        self.targets = df['piece'].values\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        # determine how many iterations in one epoch\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # called every time when the dataloader wants a sample\n",
        "        # the dataset has a list of image file names\n",
        "        # Input: dataloader provides a random index of the list\n",
        "        # Output: corresponding image and meta data\n",
        "        img_path = self.root_dir + self.file_names[index]\n",
        "        img = Image.open(img_path)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "        target = self.targets[index]\n",
        "\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PNahMLM_1lR7"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    \n",
        "    # hint: there are many \"right\" ways to do it\n",
        "    # one idea is to take the center crop without randomflip, compared to transform_train\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2WSWFBTO17FW"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = ChessDataset(foldername, df_train, transforms=transform_train)\n",
        "valid_dataset = ChessDataset(foldername, df_valid, transforms=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9XvKMxg3Erz",
        "outputId": "959cd0d3-3976-4b21-ab8d-893d52171114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (fc1): Linear(in_features=25088, out_features=5000, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (drop): Dropout(p=0.5, inplace=False)\n",
            "    (fc2): Linear(in_features=5000, out_features=7, bias=True)\n",
            "    (output): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "model = models.vgg16()\n",
        "from collections import OrderedDict\n",
        "classifier = torch.nn.Sequential(OrderedDict([('fc1', torch.nn.Linear(25088, 5000)),\n",
        "                                        ('relu', torch.nn.ReLU()),\n",
        "                                        ('drop', torch.nn.Dropout(p=0.5)),\n",
        "                                        ('fc2', torch.nn.Linear(5000, 7)),\n",
        "                                        ('output', torch.nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "model.classifier = classifier \n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S4ucxsIxLKOf"
      },
      "outputs": [],
      "source": [
        "def validation(model, validateloader, criterion):\n",
        "    \n",
        "    val_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for images, labels in iter(validateloader):\n",
        "\n",
        "        images, labels = images.to('cpu'), labels.to('cpu')\n",
        "\n",
        "        output = model.forward(images)\n",
        "        val_loss += criterion(output, labels).item()\n",
        "\n",
        "        probabilities = torch.exp(output)\n",
        "        \n",
        "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return val_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3IWTuQ_2acv",
        "outputId": "e9c4a40c-de1c-4a3d-c3f3-e6c96e55ff65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (fc1): Linear(in_features=25088, out_features=5000, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (drop): Dropout(p=0.5, inplace=False)\n",
              "    (fc2): Linear(in_features=5000, out_features=7, bias=True)\n",
              "    (output): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get GPU if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# Change input image depth for normalized images \n",
        "# model.conv1 = torch.nn.Conv2d(3, 8, kernel_size=(224, 224), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "criterion = torch.nn.NLLLoss()\n",
        "#optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.01)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.001, momentum=0.9)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIh46DSPMzRt",
        "outputId": "14958275-80ab-4f23-ef3b-8344aa6282d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/15..  Training Loss: 1.944..  Validation Loss: 1.957..  Validation Accuracy: 0.188\n",
            "Epoch: 1/15..  Training Loss: 1.947..  Validation Loss: 1.936..  Validation Accuracy: 0.287\n",
            "Epoch: 1/15..  Training Loss: 1.897..  Validation Loss: 1.915..  Validation Accuracy: 0.287\n",
            "Epoch: 1/15..  Training Loss: 1.886..  Validation Loss: 1.879..  Validation Accuracy: 0.325\n",
            "Epoch: 1/15..  Training Loss: 1.798..  Validation Loss: 1.869..  Validation Accuracy: 0.325\n",
            "Epoch: 1/15..  Training Loss: 1.719..  Validation Loss: 1.811..  Validation Accuracy: 0.325\n",
            "Epoch: 1/15..  Training Loss: 2.027..  Validation Loss: 1.848..  Validation Accuracy: 0.287\n",
            "Epoch: 2/15..  Training Loss: 1.524..  Validation Loss: 1.842..  Validation Accuracy: 0.287\n",
            "Epoch: 2/15..  Training Loss: 1.614..  Validation Loss: 1.902..  Validation Accuracy: 0.287\n",
            "Epoch: 2/15..  Training Loss: 1.864..  Validation Loss: 1.839..  Validation Accuracy: 0.325\n",
            "Epoch: 2/15..  Training Loss: 1.540..  Validation Loss: 1.983..  Validation Accuracy: 0.287\n",
            "Epoch: 2/15..  Training Loss: 1.508..  Validation Loss: 2.111..  Validation Accuracy: 0.287\n",
            "Epoch: 2/15..  Training Loss: 0.866..  Validation Loss: 2.036..  Validation Accuracy: 0.363\n",
            "Epoch: 2/15..  Training Loss: 2.545..  Validation Loss: 2.084..  Validation Accuracy: 0.287\n",
            "Epoch: 3/15..  Training Loss: 1.071..  Validation Loss: 2.004..  Validation Accuracy: 0.287\n",
            "Epoch: 3/15..  Training Loss: 1.075..  Validation Loss: 2.000..  Validation Accuracy: 0.287\n",
            "Epoch: 3/15..  Training Loss: 1.583..  Validation Loss: 1.873..  Validation Accuracy: 0.287\n",
            "Epoch: 3/15..  Training Loss: 1.743..  Validation Loss: 1.838..  Validation Accuracy: 0.287\n",
            "Epoch: 3/15..  Training Loss: 1.737..  Validation Loss: 1.777..  Validation Accuracy: 0.325\n",
            "Epoch: 3/15..  Training Loss: 1.446..  Validation Loss: 1.906..  Validation Accuracy: 0.250\n",
            "Epoch: 3/15..  Training Loss: 1.709..  Validation Loss: 1.828..  Validation Accuracy: 0.287\n",
            "Epoch: 4/15..  Training Loss: 1.422..  Validation Loss: 1.780..  Validation Accuracy: 0.287\n",
            "Epoch: 4/15..  Training Loss: 1.297..  Validation Loss: 1.842..  Validation Accuracy: 0.325\n",
            "Epoch: 4/15..  Training Loss: 1.521..  Validation Loss: 1.808..  Validation Accuracy: 0.287\n",
            "Epoch: 4/15..  Training Loss: 1.447..  Validation Loss: 1.892..  Validation Accuracy: 0.325\n",
            "Epoch: 4/15..  Training Loss: 1.519..  Validation Loss: 2.053..  Validation Accuracy: 0.325\n",
            "Epoch: 4/15..  Training Loss: 1.773..  Validation Loss: 2.025..  Validation Accuracy: 0.325\n",
            "Epoch: 4/15..  Training Loss: 1.849..  Validation Loss: 1.890..  Validation Accuracy: 0.287\n",
            "Epoch: 5/15..  Training Loss: 1.403..  Validation Loss: 1.775..  Validation Accuracy: 0.325\n",
            "Epoch: 5/15..  Training Loss: 1.181..  Validation Loss: 1.754..  Validation Accuracy: 0.363\n",
            "Epoch: 5/15..  Training Loss: 1.426..  Validation Loss: 1.905..  Validation Accuracy: 0.287\n",
            "Epoch: 5/15..  Training Loss: 1.735..  Validation Loss: 1.714..  Validation Accuracy: 0.225\n",
            "Epoch: 5/15..  Training Loss: 1.278..  Validation Loss: 1.849..  Validation Accuracy: 0.188\n",
            "Epoch: 5/15..  Training Loss: 1.808..  Validation Loss: 1.808..  Validation Accuracy: 0.287\n",
            "Epoch: 5/15..  Training Loss: 1.381..  Validation Loss: 1.685..  Validation Accuracy: 0.325\n",
            "Epoch: 6/15..  Training Loss: 1.408..  Validation Loss: 1.757..  Validation Accuracy: 0.287\n",
            "Epoch: 6/15..  Training Loss: 1.393..  Validation Loss: 1.901..  Validation Accuracy: 0.287\n",
            "Epoch: 6/15..  Training Loss: 1.754..  Validation Loss: 1.908..  Validation Accuracy: 0.325\n",
            "Epoch: 6/15..  Training Loss: 1.102..  Validation Loss: 2.040..  Validation Accuracy: 0.287\n",
            "Epoch: 6/15..  Training Loss: 1.425..  Validation Loss: 1.844..  Validation Accuracy: 0.325\n",
            "Epoch: 6/15..  Training Loss: 1.708..  Validation Loss: 2.085..  Validation Accuracy: 0.325\n",
            "Epoch: 6/15..  Training Loss: 1.113..  Validation Loss: 2.180..  Validation Accuracy: 0.287\n",
            "Epoch: 7/15..  Training Loss: 0.862..  Validation Loss: 2.176..  Validation Accuracy: 0.325\n",
            "Epoch: 7/15..  Training Loss: 1.468..  Validation Loss: 2.250..  Validation Accuracy: 0.325\n",
            "Epoch: 7/15..  Training Loss: 1.515..  Validation Loss: 2.403..  Validation Accuracy: 0.250\n",
            "Epoch: 7/15..  Training Loss: 1.751..  Validation Loss: 2.278..  Validation Accuracy: 0.250\n",
            "Epoch: 7/15..  Training Loss: 1.592..  Validation Loss: 2.073..  Validation Accuracy: 0.250\n",
            "Epoch: 7/15..  Training Loss: 1.591..  Validation Loss: 1.952..  Validation Accuracy: 0.325\n",
            "Epoch: 7/15..  Training Loss: 1.191..  Validation Loss: 1.929..  Validation Accuracy: 0.287\n",
            "Epoch: 8/15..  Training Loss: 1.197..  Validation Loss: 1.944..  Validation Accuracy: 0.287\n",
            "Epoch: 8/15..  Training Loss: 2.031..  Validation Loss: 1.917..  Validation Accuracy: 0.287\n",
            "Epoch: 8/15..  Training Loss: 1.509..  Validation Loss: 1.917..  Validation Accuracy: 0.325\n",
            "Epoch: 8/15..  Training Loss: 1.005..  Validation Loss: 1.870..  Validation Accuracy: 0.325\n",
            "Epoch: 8/15..  Training Loss: 1.491..  Validation Loss: 1.980..  Validation Accuracy: 0.287\n",
            "Epoch: 8/15..  Training Loss: 1.215..  Validation Loss: 1.941..  Validation Accuracy: 0.325\n",
            "Epoch: 8/15..  Training Loss: 2.190..  Validation Loss: 2.257..  Validation Accuracy: 0.250\n",
            "Epoch: 9/15..  Training Loss: 1.367..  Validation Loss: 1.986..  Validation Accuracy: 0.325\n",
            "Epoch: 9/15..  Training Loss: 1.441..  Validation Loss: 2.167..  Validation Accuracy: 0.287\n",
            "Epoch: 9/15..  Training Loss: 1.083..  Validation Loss: 2.081..  Validation Accuracy: 0.325\n",
            "Epoch: 9/15..  Training Loss: 1.840..  Validation Loss: 1.969..  Validation Accuracy: 0.363\n",
            "Epoch: 9/15..  Training Loss: 0.873..  Validation Loss: 2.070..  Validation Accuracy: 0.287\n",
            "Epoch: 9/15..  Training Loss: 1.802..  Validation Loss: 2.003..  Validation Accuracy: 0.363\n",
            "Epoch: 9/15..  Training Loss: 1.219..  Validation Loss: 2.057..  Validation Accuracy: 0.287\n",
            "Epoch: 10/15..  Training Loss: 1.344..  Validation Loss: 2.254..  Validation Accuracy: 0.250\n",
            "Epoch: 10/15..  Training Loss: 0.890..  Validation Loss: 1.972..  Validation Accuracy: 0.287\n",
            "Epoch: 10/15..  Training Loss: 1.763..  Validation Loss: 1.976..  Validation Accuracy: 0.287\n",
            "Epoch: 10/15..  Training Loss: 1.932..  Validation Loss: 2.060..  Validation Accuracy: 0.325\n",
            "Epoch: 10/15..  Training Loss: 1.218..  Validation Loss: 2.150..  Validation Accuracy: 0.287\n",
            "Epoch: 10/15..  Training Loss: 1.504..  Validation Loss: 1.857..  Validation Accuracy: 0.363\n",
            "Epoch: 10/15..  Training Loss: 1.029..  Validation Loss: 1.938..  Validation Accuracy: 0.287\n"
          ]
        }
      ],
      "source": [
        "def train_classifier():\n",
        "        epochs = 15\n",
        "        steps = 0\n",
        "        print_every = 1\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        for e in range(epochs):\n",
        "        \n",
        "            model.train()\n",
        "    \n",
        "            running_loss = 0\n",
        "    \n",
        "            for images, labels in iter(train_loader):\n",
        "        \n",
        "                steps += 1\n",
        "        \n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "                optimizer.zero_grad()\n",
        "        \n",
        "                output = model.forward(images)\n",
        "                loss = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        \n",
        "                running_loss += loss.item()\n",
        "        \n",
        "                if steps % print_every == 0:\n",
        "                \n",
        "                    model.eval()\n",
        "                \n",
        "                    # Turn off gradients for validation, saves memory and computations\n",
        "                    with torch.no_grad():\n",
        "                        validation_loss, accuracy = validation(model, valid_loader, criterion)\n",
        "            \n",
        "                    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                          \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                          \"Validation Loss: {:.3f}.. \".format(validation_loss/len(valid_loader)),\n",
        "                          \"Validation Accuracy: {:.3f}\".format(accuracy/len(valid_loader)))\n",
        "            \n",
        "                    running_loss = 0\n",
        "                    model.train()\n",
        "                    \n",
        "train_classifier()                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvsdfcnsoZKT",
        "outputId": "1ac7a234-f0d5-401c-8586-5438dd756ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.2874999940395355\n"
          ]
        }
      ],
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "\n",
        "    # Do validation on the test set\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        accuracy = 0\n",
        "    \n",
        "        for images, labels in iter(test_loader):\n",
        "    \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "            output = model.forward(images)\n",
        "\n",
        "            probabilities = torch.exp(output)\n",
        "        \n",
        "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        \n",
        "            accuracy += equality.type(torch.FloatTensor).mean()\n",
        "        \n",
        "        print(\"Test Accuracy: {}\".format(accuracy/len(valid_loader)))    \n",
        "        \n",
        "        \n",
        "test_accuracy(model, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrJeWeBBMv3N"
      },
      "outputs": [],
      "source": [
        "\n",
        "it = 0\n",
        "for i in range(1):\n",
        "  # Train the model:\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):      \n",
        "      print(f\"batch iteration={it}\")\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      target = target.float()\n",
        "      optimizer.zero_grad()\n",
        "      predictions = model(data)\n",
        "      real_predictions = []\n",
        "      for row in predictions:\n",
        "        guess = torch.argmax(torch.nn.functional.softmax(row)).tolist()\n",
        "        real_predictions.append(guess)\n",
        "      real_predictions = torch.tensor(real_predictions)\n",
        "      real_predictions = real_predictions.float()\n",
        "      loss = lossf(real_predictions, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      it+=1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ModelV4.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}